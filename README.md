ğŸš€ Exploring Deep Learning with MNIST Dataset ğŸš€



Iâ€™m excited to share my project on 4th week in Mindset Training where I built a Convolutional Neural Network (CNN) to classify handwritten digits using the MNIST dataset. ğŸ–¥ï¸ğŸ“Š



The MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.



ğŸ”Key Highlights:

1ï¸âƒ£ Data Preprocessing: 

Normalized images to the 0-1 range and reshaped them for the CNN.



2ï¸âƒ£ Model Architecture:

Used Conv2D layers for feature extraction.

Applied MaxPooling2D for down-sampling.

Added Dropout to prevent overfitting.

Final Dense layer with softmax activation for classification.



3ï¸âƒ£ Training:

Implemented EarlyStopping to halt training when validation loss stops improving.

Used ReduceLROnPlateau to adjust the learning rate based on validation accuracy.



4ï¸âƒ£ Results: Achieved impressive accuracy on both training and validation sets. ğŸ“ˆ

5ï¸âƒ£ Visualizations:

Plotted training and validation loss and accuracy to monitor the modelâ€™s performance.

 6ï¸âƒ£ Tools & Libraries:

 using Python on co-lab site.

Keras: For building and training the CNN.

Matplotlib & Seaborn: For visualizing the results.

tensorflow : 

free to check out the code ğŸ’¬





#DeepLearning #MachineLearning #DataScience #AI #Python #Keras #MNIST #NeuralNetworks #Tech
