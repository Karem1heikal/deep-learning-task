🚀 Exploring Deep Learning with MNIST Dataset 🚀



I’m excited to share my project on 4th week in Mindset Training where I built a Convolutional Neural Network (CNN) to classify handwritten digits using the MNIST dataset. 🖥️📊



The MNIST dataset consists of 70,000 28x28 black-and-white images of handwritten digits extracted from two NIST databases. There are 60,000 images in the training dataset and 10,000 images in the validation dataset, one class per digit so a total of 10 classes, with 7,000 images (6,000 train images and 1,000 test images) per class.



🔎Key Highlights:

1️⃣ Data Preprocessing: 

Normalized images to the 0-1 range and reshaped them for the CNN.



2️⃣ Model Architecture:

Used Conv2D layers for feature extraction.

Applied MaxPooling2D for down-sampling.

Added Dropout to prevent overfitting.

Final Dense layer with softmax activation for classification.



3️⃣ Training:

Implemented EarlyStopping to halt training when validation loss stops improving.

Used ReduceLROnPlateau to adjust the learning rate based on validation accuracy.



4️⃣ Results: Achieved impressive accuracy on both training and validation sets. 📈

5️⃣ Visualizations:

Plotted training and validation loss and accuracy to monitor the model’s performance.

 6️⃣ Tools & Libraries:

 using Python on co-lab site.

Keras: For building and training the CNN.

Matplotlib & Seaborn: For visualizing the results.

tensorflow : 

free to check out the code 💬





#DeepLearning #MachineLearning #DataScience #AI #Python #Keras #MNIST #NeuralNetworks #Tech
